{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2515305a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import ase.io\n",
    "import hydra\n",
    "import torch\n",
    "from hydra.utils import instantiate\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from pymatgen.core.structure import Structure\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "from tqdm import tqdm\n",
    "\n",
    "from mattergen.common.data.chemgraph import ChemGraph\n",
    "from mattergen.common.data.collate import collate\n",
    "from mattergen.common.data.condition_factory import ConditionLoader\n",
    "from mattergen.common.data.num_atoms_distribution import NUM_ATOMS_DISTRIBUTIONS\n",
    "from mattergen.common.data.types import TargetProperty\n",
    "from mattergen.common.utils.data_utils import lattice_matrix_to_params_torch\n",
    "from mattergen.common.utils.eval_utils import (\n",
    "    MatterGenCheckpointInfo,\n",
    "    get_crystals_list,\n",
    "    load_model_diffusion,\n",
    "    make_structure,\n",
    "    save_structures,\n",
    ")\n",
    "from mattergen.common.utils.globals import DEFAULT_SAMPLING_CONFIG_PATH, get_device\n",
    "from mattergen.diffusion.lightning_module import DiffusionLightningModule\n",
    "from mattergen.diffusion.sampling.pc_sampler import PredictorCorrector\n",
    "from mattergen.generator import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48b19b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_samples_from_sampler(\n",
    "    sampler: PredictorCorrector,\n",
    "    condition_loader: ConditionLoader,\n",
    "    properties_to_condition_on: TargetProperty | None = None,\n",
    "    output_path: Path | None = None,\n",
    "    cfg: DictConfig | None = None,\n",
    "    record_trajectories: bool = True,\n",
    ") -> list:\n",
    "    properties_to_condition_on = properties_to_condition_on or {}\n",
    "    assert all([key in sampler.diffusion_module.model.cond_fields_model_was_trained_on for key in properties_to_condition_on.keys()])  # type: ignore\n",
    "\n",
    "    all_samples_list = []\n",
    "    all_trajs_list = []\n",
    "    for conditioning_data, mask in tqdm(condition_loader, desc=\"Generating samples\"):\n",
    "        if record_trajectories:\n",
    "            sample, mean, intermediate_samples = sampler.sample_with_record(conditioning_data, mask)\n",
    "            all_trajs_list.extend(list_of_time_steps_to_list_of_trajectories(intermediate_samples))\n",
    "        else:\n",
    "            sample, mean = sampler.sample(conditioning_data, mask)\n",
    "        all_samples_list.extend(mean.to_data_list())\n",
    "    all_samples = collate(all_samples_list)\n",
    "    assert isinstance(all_samples, ChemGraph)\n",
    "    lengths, angles = lattice_matrix_to_params_torch(all_samples.cell)\n",
    "    all_samples = all_samples.replace(lengths=lengths, angles=angles)\n",
    "\n",
    "    generated_strucs = structure_from_model_output(\n",
    "        all_samples[\"pos\"].reshape(-1, 3),\n",
    "        all_samples[\"atomic_numbers\"].reshape(-1),\n",
    "        all_samples[\"lengths\"].reshape(-1, 3),\n",
    "        all_samples[\"angles\"].reshape(-1, 3),\n",
    "        all_samples[\"num_atoms\"].reshape(-1),\n",
    "    )\n",
    "\n",
    "    if output_path is not None:\n",
    "        assert cfg is not None\n",
    "        save_structures(output_path, generated_strucs)\n",
    "\n",
    "        if record_trajectories:\n",
    "            dump_trajectories(\n",
    "                output_path=output_path,\n",
    "                all_trajs_list=all_trajs_list,\n",
    "            )\n",
    "\n",
    "    return generated_strucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7300579e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mattergen.common.utils.eval_utils:Loading model from checkpoint: /home/ubt/.cache/huggingface/hub/models--microsoft--mattergen/snapshots/2092423e1f1ab5f7d792142257f0477a57628105/checkpoints/mattergen_base/checkpoints/last.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model config:\n",
      "auto_resume: true\n",
      "checkpoint_path: null\n",
      "data_module:\n",
      "  _recursive_: true\n",
      "  _target_: mattergen.common.data.datamodule.CrystDataModule\n",
      "  average_density: 0.05771451654022283\n",
      "  batch_size:\n",
      "    train: 32\n",
      "    val: 32\n",
      "  max_epochs: 2200\n",
      "  num_workers:\n",
      "    train: 0\n",
      "    val: 0\n",
      "  properties:\n",
      "  - dft_bulk_modulus\n",
      "  - dft_band_gap\n",
      "  - dft_mag_density\n",
      "  - ml_bulk_modulus\n",
      "  - hhi_score\n",
      "  - space_group\n",
      "  - energy_above_hull\n",
      "  root_dir: datasets/cache/alex_mp_20/\n",
      "  train_dataset:\n",
      "    _target_: mattergen.common.data.dataset.CrystalDataset.from_cache_path\n",
      "    cache_path: datasets/cache/alex_mp_20/train\n",
      "    properties:\n",
      "    - dft_bulk_modulus\n",
      "    - dft_band_gap\n",
      "    - dft_mag_density\n",
      "    - ml_bulk_modulus\n",
      "    - hhi_score\n",
      "    - space_group\n",
      "    - energy_above_hull\n",
      "    transforms:\n",
      "    - _partial_: true\n",
      "      _target_: mattergen.common.data.transform.symmetrize_lattice\n",
      "    - _partial_: true\n",
      "      _target_: mattergen.common.data.transform.set_chemical_system_string\n",
      "  transforms:\n",
      "  - _partial_: true\n",
      "    _target_: mattergen.common.data.transform.symmetrize_lattice\n",
      "  - _partial_: true\n",
      "    _target_: mattergen.common.data.transform.set_chemical_system_string\n",
      "  val_dataset:\n",
      "    _target_: mattergen.common.data.dataset.CrystalDataset.from_cache_path\n",
      "    cache_path: datasets/cache/alex_mp_20/val\n",
      "    properties:\n",
      "    - dft_bulk_modulus\n",
      "    - dft_band_gap\n",
      "    - dft_mag_density\n",
      "    - ml_bulk_modulus\n",
      "    - hhi_score\n",
      "    - space_group\n",
      "    - energy_above_hull\n",
      "    transforms:\n",
      "    - _partial_: true\n",
      "      _target_: mattergen.common.data.transform.symmetrize_lattice\n",
      "    - _partial_: true\n",
      "      _target_: mattergen.common.data.transform.set_chemical_system_string\n",
      "lightning_module:\n",
      "  _target_: mattergen.diffusion.lightning_module.DiffusionLightningModule\n",
      "  diffusion_module:\n",
      "    _target_: mattergen.diffusion.diffusion_module.DiffusionModule\n",
      "    corruption:\n",
      "      _target_: mattergen.diffusion.corruption.multi_corruption.MultiCorruption\n",
      "      discrete_corruptions:\n",
      "        atomic_numbers:\n",
      "          _target_: mattergen.diffusion.corruption.d3pm_corruption.D3PMCorruption\n",
      "          d3pm:\n",
      "            _target_: mattergen.diffusion.d3pm.d3pm.MaskDiffusion\n",
      "            dim: 101\n",
      "            schedule:\n",
      "              _target_: mattergen.diffusion.d3pm.d3pm.create_discrete_diffusion_schedule\n",
      "              kind: standard\n",
      "              num_steps: 1000\n",
      "          offset: 1\n",
      "      sdes:\n",
      "        cell:\n",
      "          _target_: mattergen.common.diffusion.corruption.LatticeVPSDE.from_vpsde_config\n",
      "          vpsde_config:\n",
      "            beta_max: 20\n",
      "            beta_min: 0.1\n",
      "            limit_density: 0.05771451654022283\n",
      "            limit_var_scaling_constant: 0.25\n",
      "        pos:\n",
      "          _target_: mattergen.common.diffusion.corruption.NumAtomsVarianceAdjustedWrappedVESDE\n",
      "          limit_info_key: num_atoms\n",
      "          sigma_max: 5.0\n",
      "          wrapping_boundary: 1.0\n",
      "    loss_fn:\n",
      "      _target_: mattergen.common.loss.MaterialsLoss\n",
      "      d3pm_hybrid_lambda: 0.01\n",
      "      include_atomic_numbers: true\n",
      "      include_cell: true\n",
      "      include_pos: true\n",
      "      reduce: sum\n",
      "      weights:\n",
      "        atomic_numbers: 1.0\n",
      "        cell: 1.0\n",
      "        pos: 0.1\n",
      "    model:\n",
      "      _target_: mattergen.denoiser.GemNetTDenoiser\n",
      "      atom_type_diffusion: mask\n",
      "      denoise_atom_types: true\n",
      "      gemnet:\n",
      "        _target_: mattergen.common.gemnet.gemnet.GemNetT\n",
      "        atom_embedding:\n",
      "          _target_: mattergen.common.gemnet.layers.embedding_block.AtomEmbedding\n",
      "          emb_size: 512\n",
      "          with_mask_type: true\n",
      "        cutoff: 7.0\n",
      "        emb_size_atom: 512\n",
      "        emb_size_edge: 512\n",
      "        latent_dim: 512\n",
      "        max_cell_images_per_dim: 5\n",
      "        max_neighbors: 50\n",
      "        num_blocks: 4\n",
      "        num_targets: 1\n",
      "        otf_graph: true\n",
      "        regress_stress: true\n",
      "        scale_file: /scratch/amlt_code/mattergen/common/gemnet/gemnet-dT.json\n",
      "      hidden_dim: 512\n",
      "      property_embeddings: {}\n",
      "      property_embeddings_adapt: {}\n",
      "    pre_corruption_fn:\n",
      "      _target_: mattergen.property_embeddings.SetEmbeddingType\n",
      "      dropout_fields_iid: false\n",
      "      p_unconditional: 0.2\n",
      "  optimizer_partial:\n",
      "    _partial_: true\n",
      "    _target_: torch.optim.Adam\n",
      "    lr: 0.0001\n",
      "  scheduler_partials:\n",
      "  - frequency: 1\n",
      "    interval: epoch\n",
      "    monitor: loss_train\n",
      "    scheduler:\n",
      "      _partial_: true\n",
      "      _target_: torch.optim.lr_scheduler.ReduceLROnPlateau\n",
      "      factor: 0.6\n",
      "      min_lr: 1.0e-06\n",
      "      patience: 100\n",
      "      verbose: true\n",
      "    strict: true\n",
      "load_original: false\n",
      "params: {}\n",
      "train: true\n",
      "trainer:\n",
      "  _target_: pytorch_lightning.Trainer\n",
      "  accelerator: gpu\n",
      "  accumulate_grad_batches: 1\n",
      "  callbacks:\n",
      "  - _target_: pytorch_lightning.callbacks.LearningRateMonitor\n",
      "    log_momentum: false\n",
      "    logging_interval: step\n",
      "  - _target_: pytorch_lightning.callbacks.ModelCheckpoint\n",
      "    every_n_epochs: 1\n",
      "    filename: '{epoch}-{loss_val:.2f}'\n",
      "    mode: min\n",
      "    monitor: loss_val\n",
      "    save_last: true\n",
      "    save_top_k: 1\n",
      "    verbose: false\n",
      "  - _target_: pytorch_lightning.callbacks.TQDMProgressBar\n",
      "    refresh_rate: 50\n",
      "  - _target_: mattergen.common.data.callback.SetPropertyScalers\n",
      "  check_val_every_n_epoch: 5\n",
      "  devices: 8\n",
      "  gradient_clip_algorithm: value\n",
      "  gradient_clip_val: 0.5\n",
      "  logger:\n",
      "    _target_: pytorch_lightning.loggers.WandbLogger\n",
      "    job_type: train\n",
      "    project: crystal-generation\n",
      "    settings:\n",
      "      _save_requirements: false\n",
      "      _target_: wandb.Settings\n",
      "      start_method: fork\n",
      "  max_epochs: 2200\n",
      "  num_nodes: 2\n",
      "  precision: 32\n",
      "  strategy:\n",
      "    _target_: pytorch_lightning.strategies.ddp.DDPStrategy\n",
      "    find_unused_parameters: true\n",
      "\n",
      "\n",
      "Sampling config:\n",
      "sampler_partial:\n",
      "  _target_: mattergen.diffusion.sampling.classifier_free_guidance.GuidedPredictorCorrector.from_pl_module\n",
      "  'N': 1000\n",
      "  eps_t: 0.001\n",
      "  _partial_: true\n",
      "  guidance_scale: 0.0\n",
      "  remove_conditioning_fn:\n",
      "    _target_: mattergen.property_embeddings.SetUnconditionalEmbeddingType\n",
      "  keep_conditioning_fn:\n",
      "    _target_: mattergen.property_embeddings.SetConditionalEmbeddingType\n",
      "  predictor_partials:\n",
      "    pos:\n",
      "      _target_: mattergen.diffusion.wrapped.wrapped_predictors_correctors.WrappedAncestralSamplingPredictor\n",
      "      _partial_: true\n",
      "    cell:\n",
      "      _target_: mattergen.common.diffusion.predictors_correctors.LatticeAncestralSamplingPredictor\n",
      "      _partial_: true\n",
      "    atomic_numbers:\n",
      "      _target_: mattergen.diffusion.d3pm.d3pm_predictors_correctors.D3PMAncestralSamplingPredictor\n",
      "      predict_x0: true\n",
      "      _partial_: true\n",
      "  corrector_partials:\n",
      "    pos:\n",
      "      _target_: mattergen.diffusion.wrapped.wrapped_predictors_correctors.WrappedLangevinCorrector\n",
      "      _partial_: true\n",
      "      max_step_size: 1000000.0\n",
      "      snr: 0.4\n",
      "    cell:\n",
      "      _target_: mattergen.common.diffusion.predictors_correctors.LatticeLangevinDiffCorrector\n",
      "      _partial_: true\n",
      "      max_step_size: 1000000.0\n",
      "      snr: 0.2\n",
      "  n_steps_corrector: 1\n",
      "condition_loader_partial:\n",
      "  _partial_: true\n",
      "  _target_: mattergen.common.data.condition_factory.get_number_of_atoms_condition_loader\n",
      "  num_atoms_distribution: ALEX_MP_20\n",
      "  batch_size: 16\n",
      "  num_samples: 16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating samples:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c3be6c02ea44b9ba9a61ae16ade6a8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating samples: 100%|██████████| 1/1 [05:21<00:00, 321.92s/it]\n"
     ]
    }
   ],
   "source": [
    "output_path = \"results\"\n",
    "pretrained_name = \"mattergen_base\"\n",
    "batch_size = 16\n",
    "num_batches = 1\n",
    "properties_to_condition_on = {}\n",
    "sampling_config_path = None\n",
    "sampling_config_name = \"default\"\n",
    "sampling_config_overrides = []\n",
    "record_trajectories = True\n",
    "diffusion_guidance_factor = 0.0\n",
    "target_compositions = []\n",
    "\n",
    "checkpoint_info = MatterGenCheckpointInfo.from_hf_hub(\n",
    "    pretrained_name, config_overrides=[]\n",
    ")\n",
    "generator = CrystalGenerator(\n",
    "    checkpoint_info=checkpoint_info,\n",
    "    properties_to_condition_on=properties_to_condition_on,\n",
    "    batch_size=batch_size,\n",
    "    num_batches=num_batches,\n",
    "    sampling_config_name=sampling_config_name,\n",
    "    sampling_config_path=sampling_config_path,\n",
    "    sampling_config_overrides=sampling_config_overrides,\n",
    "    record_trajectories=record_trajectories,\n",
    "    diffusion_guidance_factor=diffusion_guidance_factor,\n",
    "    target_compositions_dict=target_compositions,\n",
    ")\n",
    "generated_structures = generator.generate(output_dir=Path(output_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
